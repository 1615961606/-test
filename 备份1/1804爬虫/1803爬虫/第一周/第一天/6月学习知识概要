多线程，多进程。
爬虫的分布式。
爬取全站。
部署。
综合性项目。
免费的数据平台一般会有大量的数据。
自己获取数据通过爬虫，获取数据。
什么叫爬虫。
就是一段自动获取互联网页信息的程序。

网页的三大特征：
1.url（统一资源定位符），每一个网页都有一个url。
2.所有的网页都是通过http （https协议）实现的传输。
3.网页是超文本（HTML文档）（html，css，js）

如何完成一个爬虫项目：
1.分析需求，确定目标url（数据源）
2.模拟浏览器，根据url发起请求
3.拿到响应结果，提取目标数据。
    a.将目标数据持久化。（文件，数据库）
    b.获取当前网页下新的url，执行第二步
4.爬虫结束：知道没有新的url产生，并且待爬取的url任务全部爬取完毕，爬虫结束。

写一个爬虫具备什么知识？
1.会最基本的python基础知识
2.会一些前端知识
3.会一些后端知识
4.会一些数据存储知识
5.会爬虫知识

爬虫的分类：通用爬虫，聚焦爬虫
什么叫通用爬虫：一般情况下适用于搜索引擎，其实也是通过爬虫去获取全站的网页，需要在本地
进行镜像的备份。

得到数据后的操作：
1.预处理：对获取到的数据进行过滤。筛选，去广告等等。。
2.排名：根据网站的点击量，来进行排名。

其他的入口：
1.注册网站需要域名
2.手动提交我们的网址
聚焦爬虫：有目的性的获取数据，这样会避免获取大量的无用数据，提高获取数据的效率，
我们以后的爬虫，更多的是聚焦爬虫


http:(超文本传输协议)，用户从网络传输超文本数据到客户端，客户端拿到数据后，展示数据
https：功能于http一样，但是多了一个ssl层（安全套接字层）
1.能够实现数据的安全传输，提供一个安全渠道
2.能够确定网站的安全性和有效性

http协议的端口号：80
https协议的端口号：443

如何转换
bytes类型 ->str类型 使用decode转码
str类型->byte类型 使用encode编码